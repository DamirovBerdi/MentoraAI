const fs = require('fs');
const fetch = (global && global.fetch) ? global.fetch : (require('node-fetch'));

async function _callGemini(prompt, key){
  const model = process.env.GEMINI_MODEL || 'text-bison-001';
  const url = `https://generativelanguage.googleapis.com/v1beta2/models/${model}:generateText?key=${encodeURIComponent(key)}`;
  const body = { prompt: { text: prompt }, temperature: 0.2, maxOutputTokens: Number(process.env.GEMINI_MAX_TOKENS || 512) };
  const resp = await fetch(url, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(body) });
  const txt = await resp.text();
  let data = null;
  try{ data = JSON.parse(txt); }catch(e){ data = { raw: txt }; }
  return { status: resp.status, data, rawText: txt };
}

// generateAiExplanations(topic, searchResults, key)
async function generateAiExplanations(topic, searchResults = [], key){
  if(!topic) throw new Error('missing_topic');
  // Compose prompt asking for JSON with two fields
  const prompt = `You are an educational assistant. Produce a JSON object with two fields:\n`+
    `"simple_explanation": "A very short, simple and easy-to-understand explanation of the topic.",\n`+
    `"detailed_explanation": "A longer, in-depth explanation covering main aspects for deep understanding."\n`+
    `Respond in valid JSON only. Topic: ${topic}.`;

  // Try Gemini if key provided
  if(key){
    try{
      const resp = await _callGemini(prompt, key);
      // If status indicates rate limit or server error, throw to allow caller to handle failover
      if(resp.status === 429) {
        const err = new Error('rate_limited'); err.code = 429; throw err;
      }
      if(resp.status >= 500) { const err = new Error('server_error'); err.code = resp.status; throw err; }
      // Try to extract JSON from resp.rawText
      const m = String(resp.rawText).match(/\{[\s\S]*\}/);
      if(m){
        try{ const j = JSON.parse(m[0]);
          return { simple_explanation: j.simple_explanation || j.simple || '', detailed_explanation: j.detailed_explanation || j.detailed || j.long || '' , api_source: 'gemini', raw: resp.data };
        }catch(e){ /* fallthrough */ }
      }
      // If gemini returned structured 'candidates' or other shapes
      if(resp.data && resp.data.candidates && resp.data.candidates[0] && resp.data.candidates[0].output){
        const out = resp.data.candidates[0].output;
        const s = typeof out === 'string' ? out : (out.text || JSON.stringify(out));
        const mm = String(s).match(/\{[\s\S]*\}/);
        if(mm){ try{ const j = JSON.parse(mm[0]); return { simple_explanation: j.simple_explanation||'', detailed_explanation: j.detailed_explanation||'', api_source:'gemini', raw: resp.data }; }catch(e){} }
        return { simple_explanation: s.substring(0,400), detailed_explanation: s, api_source: 'gemini', raw: resp.data };
      }
      // Fallback: try to parse data as JSON directly
      if(resp.data && typeof resp.data === 'object'){
        const maybe = resp.data;
        if(maybe.simple_explanation || maybe.detailed_explanation) return { simple_explanation: maybe.simple_explanation||'', detailed_explanation: maybe.detailed_explanation||'', api_source:'gemini', raw: maybe };
      }
      // last resort: return raw text under detailed, and short truncated under simple
      return { simple_explanation: String(resp.rawText).slice(0,300), detailed_explanation: String(resp.rawText), api_source: 'gemini', raw: resp.data };
    }catch(e){ throw e; }
  }

  // If no gemini key, try OpenAI if configured
  const openaiKey = process.env.OPENAI_API_KEY || process.env.OPENAI_KEY;
  if(openaiKey){
    try{
      const url = 'https://api.openai.com/v1/chat/completions';
      const payload = { model: process.env.OPENAI_MODEL || 'gpt-3.5-turbo', messages: [{ role: 'system', content: 'You are an educational assistant. Answer JSON.' }, { role: 'user', content: prompt }], max_tokens: 800, temperature: 0.2 };
      const r = await fetch(url, { method: 'POST', headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${openaiKey}` }, body: JSON.stringify(payload) });
      if(r.status === 429){ const err = new Error('rate_limited'); err.code = 429; throw err; }
      const dt = await r.json();
      const txt = (dt && dt.choices && dt.choices[0] && dt.choices[0].message && dt.choices[0].message.content) || JSON.stringify(dt);
      const m = String(txt).match(/\{[\s\S]*\}/);
      if(m){ try{ const j = JSON.parse(m[0]); return { simple_explanation: j.simple_explanation||'', detailed_explanation: j.detailed_explanation||'', api_source:'openai', raw: dt }; }catch(e){} }
      return { simple_explanation: String(txt).slice(0,300), detailed_explanation: String(txt), api_source: 'openai', raw: dt };
    }catch(e){ throw e; }
  }

  // Final fallback: simple autogenerated texts
  return { simple_explanation: `Кратко: ${topic}`, detailed_explanation: `Детально: ${topic} — более длинное объяснение...`, api_source: 'fallback', raw: {} };
}

module.exports = { generateAiExplanations };
